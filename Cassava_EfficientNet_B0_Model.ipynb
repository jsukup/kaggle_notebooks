{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "Cassava - EfficientNet B0 Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jsukup/kaggle_notebooks/blob/main/Cassava_EfficientNet_B0_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1TXZIefBZRp"
      },
      "source": [
        "from google.colab import auth\r\n",
        "auth.authenticate_user()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quDI3JJfC4eG"
      },
      "source": [
        "from google.cloud import storage\r\n",
        "storage_client = storage.Client(project='kaggle-gcs')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqWLh3DjBk6j"
      },
      "source": [
        "!curl https://sdk.cloud.google.com | bash"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGML8YaoBzi8"
      },
      "source": [
        "!gcloud init"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1t1_Bwh4jCJj"
      },
      "source": [
        "import os\r\n",
        "!mkdir ./data/\r\n",
        "os.environ['KAGGLE_USERNAME'] = 'jsukup' \r\n",
        "os.environ['KAGGLE_KEY'] = 'ebdb5d1a622c34ff3e66a0d2e55e146c' \r\n",
        "!kaggle competitions download -c cassava-leaf-disease-classification -p ./data/ "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iO4V57g532PP"
      },
      "source": [
        "!kaggle competitions files -c cassava-leaf-disease-classification"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMu7fCLdjB5T"
      },
      "source": [
        "zips = tf.io.gfile.glob('./data/ld_*.tfrec.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaNfhZ5x2GlY"
      },
      "source": [
        "import zipfile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7t_rFbkAyRhJ"
      },
      "source": [
        "for tfrecs in zips:\r\n",
        "    with zipfile.ZipFile(tfrecs, 'r') as zip_ref:\r\n",
        "        zip_ref.extractall('./data/')\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "pjbahxGdm_QC"
      },
      "source": [
        "#Imports\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from functools import partial\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "5FevVYaum_QK"
      },
      "source": [
        "#Set TPU Strategy\n",
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    print(\"Device:\", tpu.master())\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "except:\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "    \n",
        "print(\"Number of replicas:\", strategy.num_replicas_in_sync)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "zlFGK-V3m_QL"
      },
      "source": [
        "# Load data from Kaggle Notebook storage\n",
        "# raw_storage = '../input/cassava-leaf-disease-classification'\n",
        "\n",
        "# with open(os.path.join(raw_storage, 'label_num_to_disease_map.json')) as f:\n",
        "#     datastore = json.load(f)\n",
        "    \n",
        "# datastore = {int(k): str(v) for k, v in datastore.items()}\n",
        "        \n",
        "# raw_labels = pd.read_csv(os.path.join(raw_storage, 'train.csv'), ) \n",
        "# raw_labels['label'].replace(datastore, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "8e4FH81fm_QL"
      },
      "source": [
        "# Calculate class weights\n",
        "# calc_weights = class_weight.compute_class_weight('balanced',\n",
        "#                                                   np.unique(raw_labels['label']),\n",
        "#                                                   raw_labels['label'])\n",
        "\n",
        "# class_weights = {i : calc_weights[i] for i in range(len(calc_weights))}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "6NT-BN_Km_QM"
      },
      "source": [
        "#HYPERPARAMETERS\n",
        "BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n",
        "IMG_SIZE = [224, 224]\n",
        "EPOCHS = 300\n",
        "LEARNING_RATE = 1e-2\n",
        "#GCP_DATASET = 'gs://kds-0ec1dec9f628bce2bc810157442805632bd221934a9e1921da420af8'\n",
        "RANDOM_SEED = 734\n",
        "MODEL_HUB_URL = 'https://tfhub.dev/tensorflow/efficientnet/b0/classification/1'\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "CLASS_WEIGHTS = {0: 3.9368905243790246,\n",
        "                1: 1.954956601187757,\n",
        "                2: 1.7935456831517183,\n",
        "                3: 0.3252317981456148,\n",
        "                4: 1.6606131160263873}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "1Zmq3g6im_QM"
      },
      "source": [
        "# Read/load tfrecords\n",
        "def decode_image(image):\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    image = tf.image.resize(image, IMG_SIZE, preserve_aspect_ratio=True)\n",
        "    image = tf.reshape(image, [*IMG_SIZE, 3])\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = tf.image.random_flip_up_down(image)\n",
        "    return image\n",
        "\n",
        "def read_tfrecord(example, labeled):\n",
        "    tfrecord_format = (\n",
        "        {\n",
        "            \"image\": tf.io.FixedLenFeature([], tf.string),\n",
        "            \"target\": tf.io.FixedLenFeature([], tf.int64),\n",
        "        }\n",
        "        if labeled else \n",
        "        {\n",
        "            \"image\": tf.io.FixedLenFeature([], tf.string)\n",
        "        }\n",
        "    )\n",
        "    example = tf.io.parse_single_example(example, tfrecord_format)\n",
        "    image = decode_image(example[\"image\"])\n",
        "    if labeled:\n",
        "        label = tf.cast(example[\"target\"], tf.int32)\n",
        "        return image, label\n",
        "    return image\n",
        "\n",
        "def load_dataset(filenames, labeled=True):\n",
        "    ignore_order = tf.data.Options()\n",
        "    ignore_order.experimental_deterministic = False  # disable order, increase speed\n",
        "    dataset = tf.data.TFRecordDataset(\n",
        "        filenames\n",
        "    )  # automatically interleaves reads from multiple files\n",
        "    dataset = dataset.with_options(\n",
        "        ignore_order\n",
        "    )  # uses data as soon as it streams in, rather than in its original order\n",
        "    dataset = dataset.map(\n",
        "        partial(read_tfrecord, labeled=labeled), num_parallel_calls=AUTOTUNE\n",
        "    )\n",
        "    # returns a dataset of (image, label) pairs if labeled=True or just images if labeled=False\n",
        "    return dataset\n",
        "\n",
        "def get_dataset(filenames, labeled=True):\n",
        "    dataset = load_dataset(filenames, labeled=labeled)\n",
        "    dataset = dataset.shuffle(2048)\n",
        "    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "    dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "    return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "7FTdjEKHm_QN"
      },
      "source": [
        "# List files\n",
        "train_files, val_files = train_test_split(tf.io.gfile.glob('./data/ld_train*.tfrec'),\n",
        "                                                           test_size=0.2,\n",
        "                                                           random_state=RANDOM_SEED)\n",
        "\n",
        "test_files = tf.io.gfile.glob('./data/ld_test*.tfrec')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Bw7ZezTUm_QN"
      },
      "source": [
        "# Get datasets\n",
        "train_dataset = get_dataset(train_files)\n",
        "val_dataset = get_dataset(val_files)\n",
        "test_dataset = get_dataset(test_files, labeled=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgYCrqmJTvuO"
      },
      "source": [
        "# Count images per dataset for additional HYPERPARAMETERS\r\n",
        "def count_data_items(filenames):\r\n",
        "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\r\n",
        "    return np.sum(n)\r\n",
        "\r\n",
        "NUM_TRAINING_IMAGES = count_data_items(train_files)\r\n",
        "NUM_VALIDATION_IMAGES = count_data_items(val_files)\r\n",
        "NUM_TEST_IMAGES = count_data_items(test_files)\r\n",
        "\r\n",
        "STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\r\n",
        "VALID_STEPS = NUM_VALIDATION_IMAGES // BATCH_SIZE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Qdli-1rwm_QN"
      },
      "source": [
        "# Examine batch of images\n",
        "# image_batch, label_batch = next(iter(train_dataset))\n",
        "\n",
        "# def show_batch(image_batch, label_batch):\n",
        "#     plt.figure(figsize=(20, 20))\n",
        "#     for n in range(25):\n",
        "#         ax = plt.subplot(5, 5, n + 1)\n",
        "#         plt.imshow(image_batch[n])\n",
        "#         if label_batch[n] in datastore:\n",
        "#             plt.title(datastore[label_batch[n]], color='w')\n",
        "#         plt.axis(\"off\")\n",
        "\n",
        "\n",
        "# show_batch(image_batch.numpy(), label_batch.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "kWjJI7Y2m_QO"
      },
      "source": [
        "# Callback instantiation\n",
        "lr_scheduler = ExponentialDecay(initial_learning_rate=LEARNING_RATE,\n",
        "                                decay_steps=10000,\n",
        "                                decay_rate=0.98)\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss',\n",
        "                               min_delta=0.001,\n",
        "                               patience=20,\n",
        "                               verbose=1,\n",
        "                               restore_best_weights=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Zi-QWUkT2pO"
      },
      "source": [
        "# Fixes TPU error when using TF Hub models\r\n",
        "os.environ[\"TFHUB_MODEL_LOAD_FORMAT\"]=\"UNCOMPRESSED\"\r\n",
        "load_options = tf.saved_model.LoadOptions(experimental_io_device='/job:localhost')\r\n",
        "reloaded_model = hub.load(MODEL_HUB_URL, options=load_options)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Czcf1SF9m_QO"
      },
      "source": [
        "# Create model\n",
        "def make_model():\n",
        "    print('Building model using TF Hub model:', MODEL_HUB_URL)\n",
        "    with strategy.scope():\n",
        "        model = tf.keras.Sequential([\n",
        "            tf.keras.layers.InputLayer(input_shape=[*IMG_SIZE, 3]),\n",
        "            hub.KerasLayer(MODEL_HUB_URL, trainable=False),\n",
        "            tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(1e-4)),\n",
        "            tf.keras.layers.Dropout(0.2),\n",
        "            tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(1e-4)),\n",
        "            tf.keras.layers.Dropout(0.2),\n",
        "            tf.keras.layers.Dense(5, activation='softmax', kernel_regularizer=tf.keras.regularizers.l2(1e-4))\n",
        "        ])\n",
        "\n",
        "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_scheduler),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['sparse_categorical_accuracy'])\n",
        "        \n",
        "    return model\n",
        "\n",
        "model = make_model()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "5nPo59Gpm_QP"
      },
      "source": [
        "# Train model\n",
        "history = model.fit(train_dataset.repeat(),\n",
        "                    steps_per_epoch=STEPS_PER_EPOCH,\n",
        "                    epochs=EPOCHS,\n",
        "                    callbacks=[early_stopping],\n",
        "                    validation_data=val_dataset,\n",
        "                    validation_steps=VALID_STEPS,\n",
        "                    class_weight=CLASS_WEIGHTS,\n",
        "                    verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lne7yfYKnMGf"
      },
      "source": [
        "# Visualize results\r\n",
        "plt.figure()\r\n",
        "plt.ylabel(\"Accuracy (training and validation)\")\r\n",
        "plt.xlabel(\"Training Steps\")\r\n",
        "plt.ylim([0,1])\r\n",
        "plt.plot(history[\"accuracy\"])\r\n",
        "plt.plot(history[\"val_accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}